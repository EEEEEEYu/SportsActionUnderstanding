##################### Training Control #####################
deterministic: False
use_compile: True
inference_mode: False # If this one is True, use inference
seed: 1234
max_epochs: 100

##################### Distributed Training Control #####################
devices: 1
num_nodes: 1
strategy: auto

##################### Dataset Setting #####################
dataset_class_name: hats
dataset_dir: ActionData
split_ratios: [0.8, 0.1, 0.1]
batch_size: 32
test_batch_size: 32
num_workers: 8
persistent_workers: True
use_augmentation: True
aug_prob: 0.5
label_is_obj: False

##################### Model Architecture #####################
model_class_name: convlstm
num_classes: 10
in_channels: 10
embedding_dim: 128
hidden_channels: 64
num_lstm_layers: 2
norm_type: 'layer'  # or 'layer'

##################### Optimizers and Loss Functions #####################
weight_decay: 1e-6
lr: 1e-3
lr_scheduler: step
lr_decay_epochs: 10
lr_decay_rate: 0.5
lr_decay_min_lr: 1e-6

###################### Tensorboard Logger Setting #####################
log_dir: 'lightning_logs'
experiment_name: 'main'

##################### Checkpoint & Restart Control #####################
enable_checkpointing: True